{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the batch layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from io import StringIO\n",
    "import boto3\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "                        bootstrap_servers='localhost:9092',\n",
    "                        auto_offset_reset='latest',  # Reset partition offsets upon OffsetOutOfRangeError\n",
    "                        group_id='test',   # must have a unique consumer group id \n",
    "                        consumer_timeout_ms=1000)  \n",
    "                                # How long to listen for messages - we do it for 10 seconds \n",
    "                                # because we poll the kafka broker only each couple of hours\n",
    "\n",
    "consumer.subscribe('DM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in consumer:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Amazon  S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id='AKIA4GFZKX7TIWS2EXYQ',\n",
    "    aws_secret_access_key='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',\n",
    ")\n",
    "\n",
    "s3_client = s3_resource.meta.client\n",
    "bucket_name = 'datampbucket'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the data into a S3 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_twitter_data(path):\n",
    "    consumer_count = 0\n",
    "    csv_buffer = StringIO() # S3 storage is object storage -> our document is just a large string\n",
    "    \n",
    "    for message in consumer: # this acts as get an iterator over the latest messages haven't seen\n",
    "        csv_buffer.write(message.value.decode() + '\\n') \n",
    "        consumer_count += 1\n",
    "        #print(message)\n",
    "    s3_resource.Object(bucket_name,path).put(Body=csv_buffer.getvalue())\n",
    "    return consumer_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### S3 bucket to Amazon Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = { 'dbname': 'dev', \n",
    "           'user':'root',\n",
    "           'pwd':'PublicoRoot1',\n",
    "           'host':'datampcluster.c7onviryvrw8.us-east-2.redshift.amazonaws.com',\n",
    "           'port':'5439'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn =  psycopg2.connect(dbname=config['dbname'], host=config['host'], \n",
    "                              port=config['port'], user=config['user'], \n",
    "                              password=config['pwd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(conn, path):\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"\"\" \n",
    "        copy \n",
    "            batch_raw\n",
    "        from \n",
    "            's3://datampbucket/\"\"\" + path + \"\"\"'  \n",
    "            access_key_id 'AKIA4GFZKX7TIWS2EXYQ'\n",
    "            secret_access_key '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'\n",
    "            delimiter ';'\n",
    "            region 'us-east-2'\n",
    "    \"\"\")\n",
    "    curs.close()\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_batch_layer(conn,consumer_count):\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"\"\" \n",
    "        drop table if exists batch_layer;\n",
    "\n",
    "        with raw_dedup as (\n",
    "        SELECT\n",
    "            distinct id,created_at,followers_count,location,favorite_count,retweet_count\n",
    "        FROM\n",
    "            batch_raw\n",
    "        ),\n",
    "        batch_result as (\n",
    "            SELECT\n",
    "                location,\n",
    "                count(id) as count_id,\n",
    "                sum(followers_count) as sum_followers_count,\n",
    "                sum(favorite_count) as sum_favorite_count,\n",
    "                sum(retweet_count) as sum_retweet_count\n",
    "            FROM\n",
    "                raw_dedup\n",
    "            group by \n",
    "                location\n",
    "        )\n",
    "        select \n",
    "            *\n",
    "        INTO\n",
    "            batch_layer\n",
    "        FROM\n",
    "            batch_result;\n",
    "            \n",
    "        insert into consumer_batch_count(counts) values ((\"\"\"+str(consumer_count)+\"\"\"));\n",
    "            \n",
    "            \n",
    "            \"\"\")\n",
    "    curs.close()\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_batch_layer(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_work(interval):\n",
    "    while True:\n",
    "        path = 'tweets/'+ time.strftime(\"%Y/%m/%d/%H\") + '_tweets_' + str(random.randint(1,1000)) + '.log'\n",
    "        consumer_count = store_twitter_data(path)\n",
    "        copy_files(conn, path)\n",
    "        compute_batch_layer(conn,consumer_count)\n",
    "        print (path)\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Load into table 'batch_raw' failed.  Check 'stl_load_errors' system table for details.\n",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-25-36a4a42743d6>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    periodic_work(60) ## 10 minutes\n",
      "  File \u001b[0;32m\"<ipython-input-24-44e77ec6c11a>\"\u001b[0m, line \u001b[0;32m5\u001b[0m, in \u001b[0;35mperiodic_work\u001b[0m\n    copy_files(conn, path)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-f9254bd60776>\"\u001b[1;36m, line \u001b[1;32m12\u001b[1;36m, in \u001b[1;35mcopy_files\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\")\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m\u001b[1;31m:\u001b[0m Load into table 'batch_raw' failed.  Check 'stl_load_errors' system table for details.\n\n"
     ]
    }
   ],
   "source": [
    "periodic_work(60) ## 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'tweets/'+ time.strftime(\"%Y/%m/%d/%H\") + '_tweets_' + str(random.randint(1,1000)) + '.log'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_count = store_twitter_data(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-16-a3ddc57f1b4a>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    copy_files(conn, path)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-f9254bd60776>\"\u001b[1;36m, line \u001b[1;32m12\u001b[1;36m, in \u001b[1;35mcopy_files\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\")\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m\u001b[1;31m:\u001b[0m current transaction is aborted, commands ignored until end of transaction block\n\n"
     ]
    }
   ],
   "source": [
    "copy_files(conn, path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interval should be an integer, the number of seconds to wait\n",
    "compute_batch_layer(conn,consumer_count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(conn, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run at the end of the day\n",
    "compute_batch_layer(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
